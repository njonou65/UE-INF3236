{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5yI4JiQV1MNW"
      },
      "source": [
        "# TP3_GROUPE-7 :Classification des courriers indesirables avec KNN\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7jjVwDb1MNf"
      },
      "source": [
        "###  Telechargement de la librairie stopword du module nltk si c est pas installer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hheaMapZNp46",
        "outputId": "b9909746-29c3-4677-b464-15597fcb20f4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /home/njonou65/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# telecharger stopword pour que le code s'execute en prenant en compte les entrees ou son utilisation apparait \n",
        "import nltk\n",
        "nltk.download(\"stopwords\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ydN2sgNfMvTu"
      },
      "outputs": [],
      "source": [
        "import os \n",
        "import string \n",
        "from nltk.corpus import stopwords \n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score #pour calculer le taux de generalisation de l'algorithme \n",
        "import numpy as np "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Uxlqz1jS0Ez"
      },
      "outputs": [],
      "source": [
        "def load_data():\n",
        "    \"\"\" fonction pour importer les spams et hams \"\"\"\n",
        "    print(\"Loading data...\")\n",
        "    \n",
        "    ham_files_location = os.listdir(\"dataset/ham/\")\n",
        "    spam_files_location = os.listdir(\"dataset/spam/\")\n",
        "    data = []\n",
        "    # charger les mails ham \n",
        "    for file_path in ham_files_location:\n",
        "      f = open(\"dataset/ham/\" + file_path, \"r\", encoding=\"utf-8\", errors=\"ignore\")\n",
        "      text = str(f.read())\n",
        "      data.append([text, \"ham\"])\n",
        "        \n",
        "    #charger les mails spam \n",
        "    for file_path in spam_files_location:\n",
        "      f = open(\"dataset/spam/\" + file_path, \"r\", encoding=\"utf-8\", errors=\"ignore\")\n",
        "      text = str(f.read())\n",
        "      data.append([text, \"spam\"])\n",
        "\n",
        "    data = np.array(data)\n",
        "    \n",
        "    print(\"flag 1: loaded data\")\n",
        "    return data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9XWrRPZbcMK"
      },
      "source": [
        "## Pretraitement des donnees"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ivA8BZ-Y1MNq"
      },
      "source": [
        "###  suppression des bruits "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6EIG_dwAbjDd"
      },
      "outputs": [],
      "source": [
        "def preprocess_data(data):\n",
        "    print(\"Preprocessing data...\")\n",
        "    \n",
        "    punc = string.punctuation           # liste des ponctuation\n",
        "    sw = stopwords.words('english')     # liste de mots de fins\n",
        "    for record in data:\n",
        "        # retirer les virgules et les symboles \n",
        "        for item in punc:\n",
        "            record[0] = record[0].replace(item, \"\")\n",
        "             # mettre toutes les lettres en miniscule supprimer les mots vides \n",
        "        splittedWords = record[0].split()\n",
        "        newText = \"\"\n",
        "        for word in splittedWords:\n",
        "            if word not in sw:\n",
        "                word = word.lower()\n",
        "                newText = newText + \" \" + word  \n",
        "        record[0] = newText\n",
        "        \n",
        "    print(\"flag 2: preprocessed data\")        \n",
        "    return data\n",
        "    # split permet de renvoyer une liste de tous les mots de l'email \n",
        "    # cette fonction permet de retirer tous les elements indesirables et renvoie un dataset plus coherent "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bX7DLiDueQj5"
      },
      "source": [
        "## Division du jeux de donnees en 2 * test + train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OIHxzxwXeY17"
      },
      "outputs": [],
      "source": [
        "def split_data(data):\n",
        "    print(\"Splitting data...\")\n",
        "    \n",
        "    features = data[:, 0]   # featurers va contenir tous les corps d'email \n",
        "    labels = data[:, 1]     # les labels des emails\n",
        "    print(labels)\n",
        "    training_data, test_data, training_labels, test_labels =\\\n",
        "        train_test_split(features, labels, test_size = 0.27, random_state = 42)\n",
        "    \n",
        "    print(\"flag 3: splitted data\")\n",
        "    return training_data, test_data, training_labels, test_labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83SFhKLOhqAb"
      },
      "source": [
        "## **Algorithme KNN**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LFRe3XFchz8T"
      },
      "outputs": [],
      "source": [
        "# permet de compter la frequence de chaque mot dans un mail et renvoie le resultat dans in dictionnaire \n",
        "def get_count(text): \n",
        "    wordCounts = dict() \n",
        "    for word in text.split(): \n",
        "        if word in wordCounts: \n",
        "            wordCounts[word] += 1 \n",
        "        else: \n",
        "            wordCounts[word] = 1 \n",
        "    \n",
        "    return wordCounts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PCGtiSj8jn1h"
      },
      "outputs": [],
      "source": [
        "def euclidean_difference(test_WordCounts, training_WordCounts):\n",
        "    \"\"\"calcul la distance euclidienne entre chaque emails\"\"\"\n",
        "  total = 0\n",
        "  for word in test_WordCounts:\n",
        "    if word in test_WordCounts and word in training_WordCounts:\n",
        "      total += (test_WordCounts[word] - training_WordCounts[word])**2\n",
        "      del training_WordCounts[word]\n",
        "    else:\n",
        "      total += test_WordCounts[word]**2\n",
        "  for word in training_WordCounts:\n",
        "    total += training_WordCounts[word]**2\n",
        "  return total**0.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BNyu-GKclOVc"
      },
      "outputs": [],
      "source": [
        "def get_class(selected_Kvalues):\n",
        "    \"\"\"classer les mails en fonctions des k voisins les plus proches\"\"\"\n",
        "    spam_count = 0\n",
        "    ham_count = 0\n",
        "    for value in selected_Kvalues:\n",
        "        if value[0] == \"spam\":\n",
        "            spam_count += 1\n",
        "        else:\n",
        "            ham_count += 1\n",
        "    if spam_count > ham_count:\n",
        "        return \"spam\"\n",
        "    else:\n",
        "        return \"ham\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "77NAEY54nKJc"
      },
      "outputs": [],
      "source": [
        "def knn_classifier(training_data, training_labels, test_data, K, tsize):\n",
        "    \"\"\"fonction de classification des emails \"\"\"\n",
        "    \n",
        "    print(\"Running KNN Classifier...\")\n",
        "    \n",
        "    result = []\n",
        "    counter = 1\n",
        "    \n",
        "    training_WordCounts = [] # compteur de mot pour les donnees d'apprentissage\n",
        "\n",
        "    for training_text in training_data:\n",
        "      training_WordCounts.append(get_count(training_text))\n",
        "\n",
        "    for test_text in test_data:\n",
        "      similarity = [] # Liste des distances euclidienne \n",
        "      test_WordCounts = get_count(test_text)  # compteur de mots pour les donnees de test\n",
        "        \n",
        "    # obtenir la difference euclidienne  \n",
        "      for index in range(len(training_data)):\n",
        "        euclidean_diff =\\\n",
        "        euclidean_difference(test_WordCounts, training_WordCounts[index])\n",
        "        similarity.append([training_labels[index], euclidean_diff])\n",
        "        \n",
        "    # on trie les distances par ordre croissant pour voir les plus proches\n",
        "      similarity = sorted(similarity, key = lambda i:i[1])\n",
        "        \n",
        "        \n",
        "    # choisir les k plus proches voisns \n",
        "      selected_Kvalues = [] \n",
        "      for i in range(K):\n",
        "        selected_Kvalues.append(similarity[i])\n",
        "        \n",
        "    # predire la classe de l'email \n",
        "      result.append(get_class(selected_Kvalues))\n",
        "    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "haRfG1KQri_B"
      },
      "source": [
        "# **Fonction principale -- execution de notre programme** "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ftJEvE5nrp0f"
      },
      "outputs": [],
      "source": [
        "def main(K):\n",
        "    data = load_data()\n",
        "    data = preprocess_data(data)\n",
        "    training_data, test_data, training_labels, test_labels = split_data(data)\n",
        "    tsize = len(test_data)\n",
        "    result = knn_classifier(training_data, training_labels, test_data[:tsize], K, tsize) \n",
        "    accuracy = accuracy_score(test_labels[:tsize], result)\n",
        "    print(\"taille des données d'entraînement\\t : \" + str(len(training_data))) \n",
        "    print(\"test data size\\t\\t : \" + str(len(test_data))) \n",
        "    print(\"valeur K\\t\\t\\ t\\t : \" + str(K)) \n",
        "    print(\"Échantillons testés\\t\\t : \" + str(tsize)) \n",
        "    print(\"% précision\\t\\t\\t : \" + str(accuracy * 100)) \n",
        "    print(\"Nombre correct\\t\\t : \" + str(int(accuracy * tsize))) \n",
        "    print(\"Nombre erroné\\t\\t : \" + str(int((1 - accuracy) * tsize)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dhsSQJdTss_B",
        "outputId": "0d185b7e-bbb3-4b67-e065-9c421b895336"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading data...\n",
            "flag 1: loaded data\n",
            "Preprocessing data...\n",
            "flag 2: preprocessed data\n",
            "Splitting data...\n",
            "['ham' 'ham' 'ham' ... 'spam' 'spam' 'spam']\n",
            "flag 3: splitted data\n",
            "Running KNN Classifier...\n",
            "taille des données d'entraînement\t : 4275\n",
            "test data size\t\t : 1582\n",
            "valeur K\t\t\\ t\t : 11\n",
            "Échantillons testés\t\t : 1582\n",
            "% précision\t\t\t : 76.23261694058155\n",
            "Nombre correct\t\t : 1206\n",
            "Nombre erroné\t\t : 376\n"
          ]
        }
      ],
      "source": [
        "main(11) "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "TP_KNN_GROUPE_7.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}